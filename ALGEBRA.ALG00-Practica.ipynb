{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√°ctica Final\n",
    "\n",
    "Enhorabuena!!! Ya el haber llegado hasta aqu√≠ es un logro m√°s en tu camino para ser un experto del Big Data y del Machine Learning!! \n",
    "\n",
    "\n",
    "<img src=\"./Images/happy.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Con esta pr√°ctica pondremos en valor todo lo que hemos visto a lo largo del m√≥dulo. Vamos all√°!! üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¬øCu√°nto cuesta hacer una cerveza?\n",
    "\n",
    "Este ejercicio pondr√° a prueba tu habilidad resolver un problema usando vectores.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python`\n",
    "- Asegurar los fundamentos matem√°ticos detr√°s de las operaciones con vectores.\n",
    "\n",
    "**Problema**: Determinar el precio de la cerveza en base a sus ingredientes.\n",
    "\n",
    "**Datos:**\n",
    "\n",
    "Considerando que los ingredientes de la cerveza son:<br>\n",
    "`ingredientes = {l√∫pulo, malta, agua, levadura}`\n",
    "\n",
    "Por otro lado tenemos el vector coste:<br>\n",
    "`coste = {l√∫pulo: 2.5, malta: 1.5, agua: 0.006, levadura: 0,45}`\n",
    "\n",
    "Por √∫ltimo tenemos el vector cantidad con lo necesario para hacer una cerveza:<br>\n",
    "`cantidad = {l√∫pulo: 6u, malta: 14u, agua: 7u, levadura: 11u}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.992000000000004"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Crear una funci√≥n para determinar el precio de la cerveza en base a sus ingregientes\n",
    "### Contruye una funci√≥n que toma como input 3 diccionarios: coste, cantidad e ingredientes\n",
    "### Devuelve el precio de la cerveza\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def precio_cerveza(coste, cantidad, ingredientes):\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"Calcula el precio de la cerveza\n",
    "    \n",
    "    Argumentos:\n",
    "        coste -- Diccionario con el coste de cada ingrediente\n",
    "        cantidad -- Diccionario con la cantidad de cada ingrediente\n",
    "        ingredientes -- Set de ingredientes que componen a la cerveza\n",
    "        \n",
    "    Ejemplo:\n",
    "        ingredientes = {'lupulo', 'malta', 'agua', 'levadura'}\n",
    "        coste = {'lupulo': 2.5, 'malta': 1.5, 'agua': 0.006, 'levadura': 0.45}\n",
    "        cantidad = {'lupulo': 6, 'agua': 7, 'malta': 14, 'levadura': 11}\n",
    "        precio_cerveza(coste, cantidad, ingredientes) #-> 40.9920\n",
    "    \"\"\"\n",
    "    price = sum([coste[k]*cantidad[k] for k in ingredientes])\n",
    "    return price\n",
    "\n",
    "ingredientes = {'lupulo', 'malta', 'agua', 'levadura'}\n",
    "coste = {'lupulo': 2.5, 'malta': 1.5, 'agua': 0.006, 'levadura': 0.45}\n",
    "cantidad = {'lupulo': 6, 'agua': 7, 'malta': 14, 'levadura': 11}\n",
    "precio_cerveza(coste, cantidad, ingredientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Singular Value Decomposition\n",
    "\n",
    "Este ejercicio pondr√° a prueba tu habilidad para usar Singular Value Decomposition para comprimir una imagen.\n",
    "\n",
    "**Objetivos**\n",
    "- Usar `Python`\n",
    "- Entender los fundamentos de `SVD`.\n",
    "\n",
    "**Problema:** Usar `SVD` para comprimir una imagen en blanco y negro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen que deberas usar es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.2 MB 1.4 MB/s            \n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 930 kB 63 kB/s             \n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Downloading numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.1 MB 698 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (21.0)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.1 MB 46 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 23 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, numpy, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.3 matplotlib-3.5.2 numpy-1.23.0 pillow-9.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.2 MB 2.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.23.0)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_190/969300423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberas crear tu propia funci√≥n para calcular el error de reconstrucci√≥n, que viene definido por:\n",
    "\n",
    "$$SSE =  \\sum_{n}^{i=1}  \\begin{Vmatrix}x_{i} -  \\widehat{x}_i \\end{Vmatrix} ^2 $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $x_i$ son los valores de la matriz original X\n",
    "- $\\widehat{x}_i$ son los valores de la matriz reconstruida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para calcular el error de reconstrucci√≥n\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sse_score(X, X_hat):\n",
    "    \"\"\"\n",
    "    Funci√≥n para calcular el error de reconstrucci√≥n\n",
    "    \n",
    "    Argumentos:\n",
    "        X -- Matriz Original\n",
    "        X_hat -- Matriz Reconstruida\n",
    "        \n",
    "    Ejemplo:\n",
    "        X = np.array([[1, 2], [3, 4]])\n",
    "        X_hat = np.array([[1.01, 1.75], [2.81, 3.99]])\n",
    "        sse = sse_score(X, X_hat) # -> 0.09879\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum((X - X_hat)**2) \n",
    "\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "X_hat = np.array([[1.01, 1.75], [2.81, 3.99]])\n",
    "sse = sse_score(X, X_hat)  \n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que ya tenemos la funci√≥n `sse` hecha, podemos pasar a construir la funci√≥n que ejecutar√° `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para ejecutar SVM\n",
    "### Tiene como entrada una matriz X\n",
    "### Devuelve U, s, Vt\n",
    "\n",
    "### Hint: S debe ser una matriz diagonal\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def svm(X):\n",
    "    \"\"\"\n",
    "    Funci√≥n que ejecuta SVM y devuelve U, S, Vt\n",
    "    \n",
    "    Argumentos:\n",
    "        X -- Matriz Original\n",
    "        \n",
    "    Ejemplo:\n",
    "        X = np.array([[1, 2], [3, 4]])\n",
    "        U, S, Vt = svm(X)  \n",
    "        \n",
    "        # -> U = array([[-0.40455358, -0.9145143 ],\n",
    "        #               [-0.9145143 ,  0.40455358]])\n",
    "        # -> S = array([[5.4649857 , 0.        ],\n",
    "        #               [0.        , 0.36596619]])   \n",
    "        # -> Vt = array([[-0.57604844, -0.81741556],\n",
    "        #                [ 0.81741556, -0.57604844]])          \n",
    "    \"\"\"\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    S = np.diag(s)\n",
    "    return U, S, Vt\n",
    "\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "U, S, Vt = svm(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en clase, las matrices obtenidas a partir de `SVM` nos sirven para reconstruir la matriz original `X`. Para ello, construye una funci√≥n que permita reconstruir la matriz original `X` a partir de `U, s, Vt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para reconstruir la matriz original a partir de U, s, Vt\n",
    "### Tiene como entrada U, s, Vt\n",
    "### Devuelve X_hat\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def reconstruction(U, S, Vt):\n",
    "    \"\"\"\n",
    "    Funci√≥n que reconstruye la matriz original a partir de U, s, Vt\n",
    "    \n",
    "    Argumentos:\n",
    "        U -- Matriz de Singular Vectors\n",
    "        s -- Matriz de Eigenvalues\n",
    "        Vt -- Matriz de Singular Vectors\n",
    "        \n",
    "    Ejemplo:\n",
    "        U = np.array([[-0.40455358, -0.9145143 ],\n",
    "                      [-0.9145143 ,  0.40455358]])\n",
    "        S = np.array([[5.4649857 , 0.        ],\n",
    "                      [0.        , 0.36596619]])\n",
    "        Vt = np.array([[-0.57604844, -0.81741556],\n",
    "                       [ 0.81741556, -0.57604844]])\n",
    "        X_hat = reconstruction(U, S, Vt)\n",
    "        \n",
    "        # X_hat -> array([[0.99999999, 1.99999998],\n",
    "        #                 [3.00000003, 4.00000001]])\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return U.dot(S.dot(Vt))\n",
    "\n",
    "U = np.array([[-0.40455358, -0.9145143 ],\n",
    "              [-0.9145143 ,  0.40455358]])\n",
    "S = np.array([[5.4649857 , 0.        ],\n",
    "              [0.        , 0.36596619]])\n",
    "Vt = np.array([[-0.57604844, -0.81741556],\n",
    "               [ 0.81741556, -0.57604844]])\n",
    "X_hat = reconstruction(U, S, Vt)\n",
    "X_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el error de reconstrucci√≥n usando la funci√≥n `sse` que has programado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = sse_score(X, X_hat)\n",
    "print(f\"El error de reconstrucci√≥n es: {sse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos programado todas las funciones necesarias para realizar `SVM` y medir el error de reconstrucci√≥n, podemos proceder a realizar la compresi√≥n de la imagen. Esta [p√°gina web](http://timbaumann.info/svd-image-compression-demo/) te ayudar√° a repasar y a entender como calcular la compresi√≥n.\n",
    "\n",
    "Debes usar la siguiente imagen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n que recibe una imagen A y devuelve la imagen comprimida\n",
    "### Tiene como entrada A y el n√∫mero de componentes para realizar la reducci√≥n de dimensionalidad\n",
    "### Devuelve la imagen comprimidad, el error de reconstrucci√≥n y el ratio de compresi√≥n\n",
    "\n",
    "### Hint: Usa las funciones anteriormente construidas\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def image_compression(A, n_components):\n",
    "    \"\"\"\n",
    "    Funci√≥n para comprimir una imagen A\n",
    "    \n",
    "    Argumentos:\n",
    "        A -- Imagen original\n",
    "        n_components -- N√∫mero de componentes\n",
    "        \n",
    "    Ejemplo:\n",
    "        A_hat, sse, comp_ratio = image_compression(A, n_components=50)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    U, S, Vt = svm(A)\n",
    "    \n",
    "    A_hat = reconstruction(U[0:U.shape[0], 0:n_components], \n",
    "                           S[0:n_components,0:n_components], \n",
    "                           Vt[0:n_components, 0:Vt.shape[1]])\n",
    "            \n",
    "    sse = np.sum((A - A_hat)**2) \n",
    "    comp_ratio = (A.shape[1]*n_components + n_components + A.shape[0]*n_components)/(A.shape[1] * A.shape[0])\n",
    "    \n",
    "    return A_hat, sse, comp_ratio\n",
    "\n",
    "A_hat, sse, comp_ratio = image_compression(A, n_components=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafica la imagen original `X` y la imagen reconstruida `X_hat`, y imprime el error de reconstrucci√≥n `sse` y el `ratio de compresion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reconstruction Error: {sse}\")\n",
    "print(f\"Ratio de compresi√≥n: {comp_ratio}\")\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(A, cmap=plt.cm.gray)\n",
    "plt.title('Original image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(A_hat, cmap=plt.cm.gray)\n",
    "plt.title('Compressed image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression - Least Squares\n",
    "\n",
    "Este ejercicio pondr√° a prueba tu habilidad para programar tu propia versi√≥n de m√≠nimos cuadrados en Python.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `Pandas` para leer y analizar los datos.\n",
    "- Asegurar los fundamentos matem√°ticos detr√°s del m√©todo de los m√≠nimos cuadrados.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresi√≥n.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso\n",
    "\n",
    "Usaremos la versi√≥n matricial de la soluci√≥n de los **m√©todos de los m√≠nimos cuadrados** para resolver este problema. Como recordatorio, expresamos los coeficientes $w_{LS}$ como un vector, y calculamos ese vector en base a la matriz de entrada $X$ y en base a $y$.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Como mostramos en clase, la matriz $X$ siempre contiene un vector de valores $1$ en la primera columna. En otras palabras:<br><br>\n",
    "\n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11}  \\\\\n",
    "1 \\  x_{21}  \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "Para dos variables, $X$ tomar√° esta forma:\n",
    " \n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11} \\  x_{12} \\\\\n",
    "1 \\  x_{21} \\  x_{22} \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1} \\  x_{n2}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "### Exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leer los datos\n",
    "tr_path = './data/train.csv'\n",
    "data = pd.read_csv(tr_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### La funci√≥n .head() muestras las primeras lineas de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lista con los nombres de las columnas\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Numero de columnas \n",
    "### Asignar el numero de columnas (int variable) a ans1\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "ans1 = len(data.columns)\n",
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Podemos graficar los datos price vs living area - Matplotlib\n",
    "\n",
    "Y = data['SalePrice']\n",
    "X = data['GrLivArea']\n",
    "\n",
    "plt.scatter(X, Y, marker = \"x\")\n",
    "\n",
    "### Anotaciones\n",
    "plt.title(\"Sales Price vs. Living Area (excl. basement)\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### price vs year - Pandas\n",
    "\n",
    "data.plot('YearBuilt', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi√≥n Lineal\n",
    "\n",
    "Ya que conocemos la ecuaci√≥n para $w_{LS}$ tenemos todo lo necesario para resolver la regresi√≥n lineal. Vamos all√°!<br><br>\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{-1}X^T y,$</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para invertir una matriz\n",
    "### Contruye una funci√≥n que toma como input una matriz\n",
    "### Devuelve la inversa de dicha matriz\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def inverse_of_matrix(mat):\n",
    "    \"\"\"Calcula y devuelve la inversa de la matriz\n",
    "    \n",
    "    Argumentos:\n",
    "        mat -- Matriz cuadrada a invertir\n",
    "        \n",
    "    Ejemplo:\n",
    "        sample_matrix = [[1, 2], [3, 4]]\n",
    "        the_inverse = inverse_of_matrix(sample_matrix)  \n",
    "        # -> the_inverse = [[-2.   1. ]\n",
    "        #                   [ 1.5 -0.5]]\n",
    "    \n",
    "    Requerimientos:\n",
    "        Esta funci√≥n depende de 'numpy.linalg.inv'\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    matrix_inverse = np.linalg.inv(mat)\n",
    "    return matrix_inverse\n",
    "\n",
    "sample_matrix = [[1, 2], [3, 4]]\n",
    "the_inverse = inverse_of_matrix(sample_matrix)  \n",
    "the_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer los datos\n",
    "\n",
    "Lo primero que debemos hacer es leer los datos, para ello construye una funci√≥n que reciba el directorio de un archivo .csv `file_path` y lo lea usando `pandas`, la funci√≥n debe devolver el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para leer un .csv\n",
    "### La funci√≥n recibe un file_path y debe devolver el dataframe\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_to_df(file_path):\n",
    "    \"\"\"Leer un archivo .csv\"\"\"\n",
    "    file_path = './data/train.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "dataframe = read_to_df(tr_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por columnas\n",
    "\n",
    "Queremos construir una funci√≥n que nos permita obtener los datos de ciertas columnas. Por ello, le pasaremos como argumento un `dataframe` y una lista con los nombres de las columnas que queremos extraer `column_names` y nos devolver√° un dataframe con solo esas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para extraer los datos de ciertas columnas\n",
    "### Como argumentos, recibe un dataframe `data_frame`y una lista con los nombres de las columnas `column_names`\n",
    "### Devuelve un dataframe con solo las columnas que le hemos especificado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def select_columns(data_frame, column_names):\n",
    "    \"\"\"Devuelve un subset del dataframe en base a los nombres de las columnas\n",
    "    \n",
    "    Argumentos:\n",
    "        data_frame -- Dataframe Object\n",
    "        column_names -- Lista con los nombres de las columnas a seleccionar\n",
    "        \n",
    "    Ejemplo:\n",
    "        data = read_into_data_frame('train.csv')\n",
    "        selected_columns = ['SalePrice', 'GrLivArea', 'YearBuilt']\n",
    "        sub_df = select_columns(data, selected_columns)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    if len(column_names) != 0: \n",
    "        df_columns = data_frame[column_names]\n",
    "        return df_columns\n",
    "    else:\n",
    "        print('No columns detected, please, insert at least a column')\n",
    "        return \n",
    "    \n",
    "data = read_to_df(tr_path)\n",
    "selected_columns = ['SalePrice', 'GrLivArea', 'YearBuilt']\n",
    "sub_df = select_columns(data, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por valores\n",
    "\n",
    "El siguiente paso es construir una funci√≥n que recibe un `data_frame`, el nombre de una columna, un valor m√≠nimo y un valor m√°ximo `cutoffs`. Nos devuelve un dataframe excluyendo las filas donde el valor de la columna indica est√° fuera de los valores m√≠nimos y m√°ximos que le hemos indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para crear un nuevo subset en base a valores\n",
    "### Como argumento recibe un dataframe y una lista de tuples\n",
    "### Tuples: (column_name, min_value, max_value)\n",
    "### Devuelve un dataframe que excluye las filas donde los valores, en la columna que le hemos indicado, exceden los valores\n",
    "### que le hemos indicado\n",
    "### No eliminar la fila si los valores son iguales al min/max valor\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def column_cutoff(data_frame, cutoffs):\n",
    "    \"\"\"Crea un nuevo dataframe en base a unos l√≠mites\n",
    "    \n",
    "    Argumentos:\n",
    "        data_frame -- Dataframe Object\n",
    "        cutoffs -- Lista de tuples con el siguiente formato:\n",
    "        (column_name, min_value, max_value)\n",
    "        \n",
    "    Ejemplo:\n",
    "        data_frame = read_into_data_frame('train.csv')\n",
    "        # Remove data points with SalePrice < $50,000\n",
    "        # Remove data points with GrLiveAre > 4,000 square feet\n",
    "        cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "        selected_data = column_cutoff(data_frame, cutoffs)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    for i in range(len(cutoffs)):\n",
    "        column = cutoffs[i][0]\n",
    "        min_value = cutoffs[i][1]\n",
    "        max_value = cutoffs[i][2]\n",
    "        df_cutoff = data_frame[(data_frame[column] >= min_value) & (data_frame[column] <= max_value)]\n",
    "\n",
    "        data_frame = df_cutoff\n",
    "    return df_cutoff\n",
    "\n",
    "data_frame = read_to_df(tr_path)\n",
    "cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "selected_data = column_cutoff(data_frame, cutoffs)\n",
    "\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√≠nimos Cuadrados / Least Squares\n",
    "\n",
    "Ahora, implementar√°s la ecuaci√≥n $w_{LS}$:\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{‚àí1}X^T y,$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para resolver la ecuaci√≥n wLS\n",
    "### Toma como argumentos dos matrices, una para X y otra para y\n",
    "### Asumimos que las matrices tienen las dimensiones correctas\n",
    "\n",
    "### Paso 1: Asegurate que n > d. \n",
    "### Es decir, que el n√∫mero de observaciones es mayor que el n√∫mero de dimensiones.\n",
    "### O lo que es lo mismo, que el n√∫mero de filas de cada matriz sea mayor que el n√∫mero de columnas\n",
    "### Si no es as√≠, debes transponer las matrices\n",
    "\n",
    "### Paso 2: Debes a√±adir a la matriz X un vector columna del tama√±o (n x 1)\n",
    "\n",
    "### Paso 3: Usa la ecuaci√≥n de arriba para obtener wLS\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def least_squares_weights(input_x, target_y):\n",
    "    \"\"\"Resuelve la ecuaci√≥n para wLS\n",
    "    \n",
    "    Argumentos:\n",
    "        input_x -- Matriz con los datos de entrenamiento\n",
    "        target_y -- Vector con los datos de salida\n",
    "        \n",
    "    Ejemplo:\n",
    "        import numpy as np\n",
    "        training_y = np.array([[208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000]])\n",
    "        training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001, \n",
    "                                1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "        weights = least_squares_weights(training_x, training_y)\n",
    "        \n",
    "        print(weights)  #--> np.array([[-2.29223802e+06],\n",
    "                        #              [ 5.92536529e+01],\n",
    "                        #              [ 1.20780450e+03]])\n",
    "                           \n",
    "        print(weights[1][0]) #--> 59.25365290008861\n",
    "    \n",
    "    Asumimos:\n",
    "        -- target_y es un vector con el mismo n√∫mero de observaciones que input_x\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "     \n",
    "    x_shape = input_x.shape\n",
    "    y_shape = target_y.shape\n",
    "    \n",
    "    \n",
    "    if x_shape[0] < x_shape[1]:\n",
    "        input_x = np.transpose(input_x)\n",
    "    if y_shape[0] < y_shape[1]:\n",
    "        target_y = np.transpose(target_y)\n",
    "\n",
    "    n = input_x.shape[0]\n",
    "    ones_array = np.ones((n, 1))\n",
    "\n",
    "    \n",
    "    input_X = np.concatenate((ones_array, input_x), axis=1)\n",
    "\n",
    "    \n",
    "    w = np.dot(np.linalg.inv(np.dot(input_X.T, input_X)), np.dot(input_X.T, target_y))\n",
    "    \n",
    "    return w\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "training_y = np.array([[208500, 181500, 223500, \n",
    "                        140000, 250000, 143000, \n",
    "                        307000, 200000, 129900, \n",
    "                        118000]])\n",
    "training_x = np.array([[1710, 1262, 1786, \n",
    "                        1717, 2198, 1362, \n",
    "                        1694, 2090, 1774, \n",
    "                        1077], \n",
    "                       [2003, 1976, 2001, \n",
    "                        1915, 2000, 1993, \n",
    "                        2004, 1973, 1931, \n",
    "                        1939]])\n",
    "weights = least_squares_weights(training_x, training_y)\n",
    "\n",
    "print(weights) \n",
    "\n",
    "print(weights[1][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en datos reales\n",
    "\n",
    "Ahora que ya hemos programado todas las funciones necesarias para calcular la regresi√≥n lineal vamos a aplicar al conjunto de datos que hab√≠amos seleccionado al principio. \n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Si tus funciones est√°n correctamente programadas, la siguiente celda correr√° sin problemas üòÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/train.csv'\n",
    "df = read_to_df(test_path)\n",
    "df_sub = select_columns(df, ['SalePrice', 'GrLivArea', 'YearBuilt'])\n",
    "\n",
    "cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "df_sub_cutoff = column_cutoff(df_sub, cutoffs)\n",
    "\n",
    "X = df_sub_cutoff['GrLivArea'].values\n",
    "Y = df_sub_cutoff['SalePrice'].values\n",
    "\n",
    "### reshaping for input into function\n",
    "training_y = np.array([Y])\n",
    "training_x = np.array([X])\n",
    "\n",
    "weights = least_squares_weights(training_x, training_y)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = np.max(X) + 500\n",
    "min_X = np.min(X) - 500\n",
    "\n",
    "### Choose points evenly spaced between min_x in max_x\n",
    "reg_x = np.linspace(min_X, max_X, 1000)\n",
    "\n",
    "### Use the equation for our line to calculate y values\n",
    "reg_y = weights[0][0] + weights[1][0] * reg_x\n",
    "\n",
    "plt.plot(reg_x, reg_y, color='#58b970', label='Regression Line')\n",
    "plt.scatter(X, Y, c='k', label='Data')\n",
    "\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementaci√≥n con sklearn\n",
    "\n",
    "Podemos comprobar como el resultado de nuestro c√≥digo es exactamente igual al resultado de `sklearn`. Enhorabuena! Has programado tu propia **regresi√≥n lineal!!** üòÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "### SKLearn requiere un array 2-dimensional X y 1 dimensional y.\n",
    "### skl_X = (n,1); skl_Y = (n,)\n",
    "skl_X = df_sub_cutoff[['GrLivArea']]\n",
    "skl_Y = df_sub_cutoff['SalePrice']\n",
    "\n",
    "lr.fit(skl_X,skl_Y)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"Coefficient:\", lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression - Gradient Descent\n",
    "\n",
    "En este ejercicio resolveras el mismo problema anterior pero usando **Gradient Descent**\n",
    "\n",
    "**Objetivos**:\n",
    "- Asegurar los fundamentos matem√°ticos detr√°s del Gradient Descent.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresi√≥n.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "**Repaso:**\n",
    "\n",
    "$$ RSS(w) = \\sum_{n=1}^{N}[y_n-f(x_n)]^2 =  \\sum_{n=1}^{N}[y_n- (w_0 + \\sum_{d=1}^{D}w_dx_{nd}) ]^2 .$$\n",
    "\n",
    "Loss function:\n",
    "\n",
    "$$ RSS(w) = \\frac{1}{2}\\sum_{n=1}^{N}[y_n-f(x_n)]^2$$\n",
    "\n",
    "Y lo que queremos es minimizar esta distancia, para que el modelo se acerque lo m√°ximo posible a los valores verdaderos.\n",
    "\n",
    "$$\\nabla RSS(w) = X^T(Xw^t-y)$$\n",
    "\n",
    "En resumen, el gradient descendiente para una regresi√≥n lineal, se basa en resolver esta ecuaci√≥n de forma iterativa:\n",
    "\n",
    "$$w^{t+1} = w^t - \\eta * \\nabla RSS(w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer datos\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Extraer dichas columnas\n",
    "newData = data[['GrLivArea','SalePrice']]\n",
    "print(newData.head())\n",
    "\n",
    "# Contruir x - y\n",
    "x = newData['GrLivArea']\n",
    "y = newData['SalePrice']\n",
    "\n",
    "# Standarizar los datos\n",
    "x = (x - x.mean()) / x.std()\n",
    "x = np.c_[np.ones(x.shape[0]), x] \n",
    "\n",
    "print(\"Shape of X: \", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Funci√≥n para encontrar los valores w usando Gradient Descent\n",
    "### Toma como argumentos: X, y, w, n_iterations, eta\n",
    "### Completa la funci√≥n a√±adiendo la loss funci√≥n y la updating rule\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def gradient_descent(x, y, w, iterations, eta):\n",
    "    \"\"\"Gradient descent\n",
    "    \n",
    "    Argumentos:\n",
    "        x -- Matriz con los datos de entrenamiento\n",
    "        y -- Vector con los datos de salida\n",
    "        w -- Vector aleatoriamente inicializado\n",
    "        iterations -- N√∫mero de iteraciones\n",
    "        eta -- Learning Rate\n",
    "        \n",
    "    Ejemplo:\n",
    "        import numpy as np\n",
    "\n",
    "        # Learning rate\n",
    "        eta = 0.01 \n",
    "\n",
    "        # N√∫mero de iteraciones\n",
    "        iterations = 2000 #No. of iterations\n",
    "\n",
    "        # Seed para inicializar w\n",
    "        np.random.seed(123)\n",
    "        w0 = np.random.rand(2)\n",
    "        \n",
    "        training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000])\n",
    "        training_x = np.array([[ 1.        ,  0.37020659],\n",
    "                               [ 1.        , -0.48234664],\n",
    "                               [ 1.        ,  0.51483616],\n",
    "                               [ 1.        ,  0.38352774],\n",
    "                               [ 1.        ,  1.29888065]])\n",
    "                            \n",
    "        weights, loss = gradient_descent(training_x, training_y, w0, iterations, eta)\n",
    "        \n",
    "        print(weights[-1])  #--> np.array([183845.82320222  40415.66453324])\n",
    "    \"\"\"\n",
    "    \n",
    "    past_loss = []\n",
    "    past_w = [w]\n",
    "    n = y.size\n",
    "    for i in range(iterations):\n",
    "        prediction = np.dot(x, w)\n",
    "        error = prediction - y\n",
    "        \n",
    "        # TODO: Define Loss function\n",
    "        #=============\n",
    "        \n",
    "        #=============\n",
    "        past_loss.append(loss)\n",
    "        \n",
    "        GradRss = np.dot(x.T, error)\n",
    "        \n",
    "        # TODO: Define updating rule\n",
    "        #=============\n",
    "        \n",
    "        #=============\n",
    "        past_w.append(w)\n",
    "        \n",
    "    return past_w, past_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "eta = 0.01 \n",
    "\n",
    "\n",
    "iterations = 2000 \n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "\n",
    "training_y = np.array([208500, 181500, 223500, \n",
    "                        140000, 250000])\n",
    "training_x = np.array([[ 1.        ,  0.37020659],\n",
    "                       [ 1.        , -0.48234664],\n",
    "                       [ 1.        ,  0.51483616],\n",
    "                       [ 1.        ,  0.38352774],\n",
    "                       [ 1.        ,  1.29888065]])\n",
    "\n",
    "weights, loss = gradient_descent(training_x, training_y, w0, iterations, eta)\n",
    "\n",
    "print(weights[-1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez construida nuestra funci√≥n para el Gradient Descent podemos usarla para encontrar los valores optimos de $w$. **Prueba a modificar el learning rate para ver la convergencia del Gradient Descent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.01 \n",
    "\n",
    "# N√∫mero de iteraciones\n",
    "iterations = 2000 #No. of iterations\n",
    "\n",
    "# Seed para inicializar w\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "\n",
    "weights, loss = gradient_descent(x, y, w0, iterations, eta)\n",
    "\n",
    "print(weights[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado la siguiente funci√≥n para ver como Gradient Descent encuentra el resultado final - **Tarda un poco**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Definir figure\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.title('Sale Price vs Living Area')\n",
    "plt.xlabel('Living Area in square feet (normalised)')\n",
    "plt.ylabel('Sale Price ($)')\n",
    "plt.scatter(x[:,1], y, color='red')\n",
    "line, = ax.plot([], [], lw=2)\n",
    "annotation = ax.text(-1, 700000, '')\n",
    "annotation.set_animated(True)\n",
    "plt.close()\n",
    "\n",
    "# Generar animacion de los datos\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    annotation.set_text('')\n",
    "    return line, annotation\n",
    "\n",
    "# Funci√≥n para la animaci√≥n\n",
    "def animate(i):\n",
    "    x = np.linspace(-5, 20, 1000)\n",
    "    y = weights[i][1]*x + weights[i][0]\n",
    "    line.set_data(x, y)\n",
    "    annotation.set_text('loss = %.2f e10' % (loss[i]/10000000000))\n",
    "    return line, annotation\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=0, blit=True)\n",
    "\n",
    "anim.save('animation.gif', writer='imagemagick', fps = 30)\n",
    "\n",
    "# Visualizar la animaci√≥n\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = 'animation.gif'\n",
    "\n",
    "video = io.open(filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Opcional) - Calculando similitud entre p√°ginas web\n",
    "\n",
    "Este ejercicio pondr√° a prueba tu capacidad para encontrar la similitud entre vectores usando cosine similarity.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `BeautifulSoup` para \"scrapear\" p√°ginas webs.\n",
    "- Asegurar los fundamentos matem√°ticos detr√°s del cosine similarity.\n",
    "\n",
    "**Problema**: Dadas N p√°ginas web, extraer el texto de ellas y determinar la similitud.\n",
    "\n",
    "### Repaso\n",
    "\n",
    "Como recordar√°s, podemos medir la similitud entre vectores usando la siguiente ecuaci√≥n:<br>\n",
    "\n",
    "<center>$\\overrightarrow{u} \\cdot \\overrightarrow{v} = |\\overrightarrow{u}||\\overrightarrow{v}| \\cos \\theta $</center>\n",
    "\n",
    "Que podemos reescribir de la siguiente forma:<br>\n",
    "\n",
    "<center>$\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$</center>\n",
    "\n",
    "La **similitud** va a venir dada por el √°ngulo $\\theta$, que nos indicar√° lo siguiente:\n",
    "\n",
    "<img src=\"./Images/cosine_sim.png\" width=70%/>\n",
    "\n",
    "### Web scraping\n",
    "\n",
    "La t√©cnica llamada `web scraping` es la utilizada normalmente para extraer contenido de p√°ginas webs y posteriormente procesarlos. Por ejemplo, si quisieramos construir una base de datos para entrenar un modelo con im√°genes de ropa para hombres, podr√≠amos intentar \"scrapear\" dicha secci√≥n de la p√°gina web del El Corte Ingl√©s para conseguir las im√°genes (no es tan f√°cil como suena)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas librerias deben ser instaladas para hacer este ejercicio\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://es.wikipedia.org/wiki/Canis_lupus_familiaris\"\n",
    "\n",
    "def parse_from_url(url):\n",
    "    \"\"\"\n",
    "    Funci√≥n para extraer el contenido (raw text) de una p√°gina web\n",
    "    \"\"\"\n",
    "    \n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\" )\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "        \n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Eliminar saltos de linea\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "parse_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una funci√≥n que reciba una lista de urls\n",
    "### Aplica web scraping a cada una de ellas para extraer el contenido\n",
    "### Y devuelva un diccionario con el contenido por cada url\n",
    "\n",
    "### HINT: Usa la funci√≥n anterior\n",
    "### NOTE: Suele tardar un poco en extraer el contenido de las paginas web\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def get_content(url_ls):\n",
    "    \"\"\"Extrae el contenido de una lista de urls\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista con urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        url2content = get_content(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Esta funci√≥n depende de 'parse_from_url()'\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado\n",
    "\n",
    "Como es l√≥gico, no podemos resolver esta ecuaci√≥n $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$ usando texto sin m√°s, debemos convertir cada p√°gina web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una funci√≥n que reciba texto\n",
    "### Y devuelva una lista con el texto separado por espacios\n",
    "### Adem√°s del set de la lista\n",
    "### \"hola que que tal\" - [\"hola\", \"que\", \"que\", \"tal\"], {\"hola\", \"que\", \"tal\"}\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"Divide el texto en palabras\n",
    "    \n",
    "    Argumentos:\n",
    "        text -- String\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = \"Hola me llamo llamo Alex y estamos aprendiendo Algebra y estamos bien\"\n",
    "        \n",
    "        tokens_txt, set_txt = tokenizer(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        No uses ning√∫n tokenizer ya implementado (nltk, spacy, ...)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es crear un conjunto con las palabras de ambas p√°ginas web (uni√≥n), por ejemplo:\n",
    "\n",
    "- Los perros son maravillosos...\n",
    "- Los maravillosos a√±os 80...\n",
    "\n",
    "Por tanto, el conjunto para estas dos frases ser√≠a `{\"los\", \"perros\", \"son\", \"maravillosos\", \"a√±os\", \"80\"}`. Debemos realizar esto para todas las combinaciones posibles, es decir:\n",
    "\n",
    "- web_1\n",
    "- web_2\n",
    "- web_3\n",
    "\n",
    "En este caso, las combinaciones ser√≠an (no importa el orden) `[web_1, web_2]`, `[web_1, web_3]`, `[web_2, web_3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una funci√≥n que recibe una lista de N p√°ginas web\n",
    "### Y calcula todas las combinaciones posibles entre ellas, no importa el orden\n",
    "### [web_1, web_2, web_3, ...]\n",
    "### Devuelve una lista de tuples con las combinaciones [(web_1, web_2), (web_1, web_3), ...]\n",
    "\n",
    "# HINT: Puedes implementar esta funci√≥n como quieras pero la librer√≠a itertools \n",
    "#       proporciona una funci√≥n llamada `combinations` para realizar esta tarea.\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "import itertools\n",
    "    \n",
    "def combinations(url_ls):\n",
    "    \"\"\"Calcula todas las combinaciones posibles entre los elementos de una lista\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista de urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        permutation = combinations(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Puedes implementar esta funci√≥n como quieras pero la librer√≠a itertools \n",
    "        proporciona una funci√≥n llamada `combinations` para realizar esta tarea.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una funci√≥n que recibe una lista con tuples\n",
    "### [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "### Y devuelve una lista con la union de los conjuntos\n",
    "### [({'que', 'hola', 'es', 'guay'}), ({'que', 'hola', 'madrid', 'la', 'es'})]\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def union(comb_ls):\n",
    "    \"\"\"Calcula la uni√≥n por cada tuple de una lista \n",
    "    \n",
    "    Argumentos:\n",
    "        comb_ls -- Lista de tuples\n",
    "        \n",
    "    Ejemplo:\n",
    "        comb_ls = [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "        \n",
    "        union_ls = union(comb_ls)  # -> [{'es', 'que', 'hola', 'guay'}, {'es', 'que', 'hola', 'madrid', 'la'}]\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos una lista de conjuntos por cada par de p√°ginas web, podemos convertir el texto de la p√°gina web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set2vector(tokens_web1, tokens_web_2, set_web1, set_web2):\n",
    "    \"\"\"\n",
    "    Funci√≥n para convertir un conjunto a vector\n",
    "    \n",
    "    Argumentos:\n",
    "        tokens_web1 -- Contenido tokenizado de p√°gina web 1\n",
    "        tokens_web_2 -- Contenido tokenizado de p√°gina web 2\n",
    "        set_web1 -- Conjunto de palabras de la p√°gina web 1\n",
    "        set_web2 -- Conjunto de palabras de la p√°gina web 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "        tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "        set_web1 = {\"hola\", \"que\", \"tal\"}\n",
    "        set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "        union_ls = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  \n",
    "        \n",
    "    Requerimientos:\n",
    "        Depende de la funci√≥n `union()`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unimos los conjuntos\n",
    "    join_set = union([(set_web1, set_web2)])[0]\n",
    "    \n",
    "    web1_array = []\n",
    "    web2_array = [] \n",
    "\n",
    "    for word in join_set:\n",
    "        if word in tokens_web1:\n",
    "            web1_array.append(1)\n",
    "        else:\n",
    "            web1_array.append(0)\n",
    "        if word in tokens_web_2:\n",
    "            web2_array.append(1)\n",
    "        else:\n",
    "            web2_array.append(0)\n",
    "\n",
    "    return web1_array, web2_array\n",
    "\n",
    "tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "set_web1 = {\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"}\n",
    "set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "web1_array, web2_array = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "Por √∫ltimo, ya podemos implementar la ecuaci√≥n: $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una funci√≥n que recibe dos vectores, u y v\n",
    "### Y devuelva la similaridad entre ambos vectores\n",
    "###\n",
    "### Paso 1: Si u y v son listas -> Convertirlo a arrays\n",
    "###\n",
    "### Paso 2: Calcula la similaridad entre ambos vectores\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Calcula la similaridad entre dos vectores\n",
    "    \n",
    "    Argumentos:\n",
    "        u -- Vector 1\n",
    "        v -- Vector 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        u = np.array([1, 2, 3])\n",
    "        v = np.array([3, 2, 1])\n",
    "        \n",
    "        similarity = cosine_similarity(u, v)  # -> 0.71428\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def websites_sim(url_ls):\n",
    "    \"\"\"Funci√≥n para calcular la similaridad entre p√°ginas web\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Listas de p√°ginas web\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        similarity_ls = websites_sim(url_ls)  \n",
    "    \"\"\"\n",
    "    \n",
    "    url2content = get_content(url_ls)\n",
    "    \n",
    "    # Creamos un diccionario donde cada url tendr√° su contenido tokenizado y su conjunto\n",
    "    url_dict = {}\n",
    "    for url, content in url2content.items():\n",
    "        toks, sets = tokenizer(content)\n",
    "        url_dict[url] = {'tokens': toks,\n",
    "                        'unique_tokens': sets}\n",
    "    \n",
    "    # Calculamos todas las combinaciones posibles de las direcciones de las p√°ginas web\n",
    "    comb_ls = combinations(url_ls)\n",
    "\n",
    "    # Usando comb_ls y la funci√≥n `set2vector()` convertimos cada p√°gina web a vectores\n",
    "    print(\"Similaridad: \")\n",
    "    for el in comb_ls:\n",
    "        # Obtenemos los tokens y el conjunto para cada p√°gina web\n",
    "        token_1 = url_dict[el[0]]['tokens']\n",
    "        token_2 = url_dict[el[1]]['tokens']\n",
    "        set_1 = url_dict[el[0]]['unique_tokens']\n",
    "        set_2 = url_dict[el[1]]['unique_tokens']\n",
    "        array_web1, array_web2 = set2vector(token_1, token_2, set_1, set_2)\n",
    "        similarity = cosine_similarity(array_web1, array_web2)\n",
    "        \n",
    "        print(\"{} vs {} - {}\".format(el[0], el[1], round(similarity, 3)))\n",
    "\n",
    "                      \n",
    "url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "\n",
    "similarity_ls = websites_sim(url_ls) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
